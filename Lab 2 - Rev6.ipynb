{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATUS OF PAPER:  \n",
    "  \n",
    "  \n",
    "<font color='green'>  \n",
    "100% - Define and prep class variables (10 points)  </font>  \n",
    "<font color='green'>100% - Describe the final dataset (5 points)  </font>  \n",
    "<font color='green'>100% -  Choose and explain your evaluation metrics (10 points)  </font>   \n",
    "<font color='green'>100% -  Choose the method for training/testing split (10 points)  </font>  \n",
    "<font color='green'>100% -  Create three classification models (20 points)  </font>   \n",
    "<font color='blue'>20% -  Analyze results (10 points)  </font>  \n",
    "<font color='blue'>20% -  Discuss advantages of each classification model (10 points)  </font>   \n",
    "<font color='red'>0% -  Which attributes are most important? (10 points)  </font>  \n",
    "<font color='green'>100% - How useful is your model? (5 points)  </font>  \n",
    "<font color='blue'>20% -  Exceptional work (10 points)  </font>  \n",
    "  \n",
    "\n",
    "Minimum work still needed:  \n",
    "Visualizations for the Analyze Results section  \n",
    "Statistical analysis for 95% certainty of difference for the Discuss Advantages section  \n",
    "The entirety of the \"Which attributes are most important\" section.  \n",
    "Getting the SVM classification to work for exceptional work\n",
    "finding and including some other exceptional work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Classification and/or Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Dataset Selection  \n",
    "\n",
    "<font color='blue'> Select a dataset identically to the way you selected for the first project work week and mini-project.\n",
    "You are not required to use the same dataset that you used in the past, but you are encouraged.\n",
    "You must identify two tasks from the dataset to regress or classify. That is:  \n",
    "• two classification tasks OR  \n",
    "• two regression tasks OR  \n",
    "• one classification task and one regression task  \n",
    "For example, if your dataset was from the diabetes data you might try to predict two tasks: (1)\n",
    "classifying if a patient will be readmitted within a 30 day period or not, and (2) regressing what the\n",
    "total number of days a patient will spend in the hospital, given their history and specifics of the\n",
    "encounter like tests administered and previous admittance. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab assignment we have chosen to use the \"income\" dataset that was donated to the UCI machine learning database.  This dataset includes information on over 32,000 patients, and the information gathered includes their age, marital status, education, income, and others.  \n",
    "  \n",
    "There will be two classification tasks that we will perform on this data.  The first will be classifying individuals into two separate classes based upon whether or not they earned less than or more than 50,000 dollars a year.  This is the classification task for which the data was gathered, and will help provide insight into which factors best predict an individual's income level.  \n",
    "  \n",
    "The second classification task will be to classify individuals by their marital status such as married, never married, and divorced.  This will provide insight into how well economic factors can predict an individuals marital status to answer questions such as \"do married people generally earn more?\" or \"does earning more increase the odds of being or becoming divorced?\".  These questions can be of great interest to social scientists and legislators who may want to put forward new policy to account for or attempt to influence any trends found by these classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (15 points total)\n",
    "### • [10 points] Define and prepare your class variables.  \n",
    "<font color='blue'>Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for\n",
    "dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for\n",
    "the analysis.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below we will be importing the income dataset and preparing the class variables.  All variables in this dataset are either categorical variables or integer variables.  The integer variables are of different scales, for example the hours-per-week variable is an integer that generally falls within the range of 0-40, while the capital-gain variable can have values in the thousands.  For this reason we will be standardizing the integer values as part of our pre-processing.  \n",
    "  \n",
    "Furthermore, the categorical variables are represented by strings, which can pose issues with some of the processes we will be using in our classification tasks.  Therefore we will also be encoding the strings as integer labels as part of our preprocessing steps as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "# This code imports the packages we will be using, and sets parameters for the matplotlib.pylab package.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics as mt\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to where all of the data set files resides \n",
    "path = 'C:/Users/Bear/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education-num     32561 non-null int64\n",
      "marital-status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capital-gain      32561 non-null int64\n",
      "capital-loss      32561 non-null int64\n",
      "hours-per-week    32561 non-null int64\n",
      "native-country    32561 non-null object\n",
      "target            32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 4.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code reads in the initial csv file\n",
    "filename = path + '\\income.csv'\n",
    "df_income = pd.read_csv(filename) # read in the csv file\n",
    "df_income.info()\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This code creates a target array with 0 representing under 50,000 USD a year and 1 representing over 50,000 USD a year\n",
    "\n",
    "i = 0\n",
    "rangeLength = len(df_income)\n",
    "#print(rangeLength)\n",
    "target = []\n",
    "for i in range(0,rangeLength):\n",
    "    if df_income['target'].iloc[i] == \" <=50K\":\n",
    "        target.append(0)\n",
    "    else:\n",
    "        target.append(1)\n",
    "#print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States       0  \n",
       "1             0             0              13   United-States       0  \n",
       "2             0             0              40   United-States       0  \n",
       "3             0             0              40   United-States       0  \n",
       "4             0             0              40            Cuba       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code replaces the existing 'target' variable with our newly created array of integer representations.\n",
    "\n",
    "df_income['income'] = target\n",
    "df_income = df_income.drop('target', axis=1)\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education-num       marital-status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race      sex  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country  income  \n",
       "0             0              40   United-States       0  \n",
       "1             0              13   United-States       0  \n",
       "2             0              40   United-States       0  \n",
       "3             0              40   United-States       0  \n",
       "4             0              40            Cuba       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code drops the \"fnlwgt\" variable, which is a weighting variable used for stratified sampling that is not going to be \n",
    "# useful for us in our classification tasks.\n",
    "\n",
    "df_income = df_income.drop('fnlwgt', axis=1)\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.174022</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education-num       marital-status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race      sex  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male      2.174022   \n",
       "1     Exec-managerial         Husband   White     Male      0.000000   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male      0.000000   \n",
       "3   Handlers-cleaners         Husband   Black     Male      0.000000   \n",
       "4      Prof-specialty            Wife   Black   Female      0.000000   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country  income  \n",
       "0             0              40   United-States       0  \n",
       "1             0              13   United-States       0  \n",
       "2             0              40   United-States       0  \n",
       "3             0              40   United-States       0  \n",
       "4             0              40            Cuba       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code standardizes the two continuous variables related to capital gain and capital loss.\n",
    "# We decided not to standardize any other variables as they are all either categorical variables, or they are on a \n",
    "# small scale that makes less sense if standardizes such as hours per week, age, and education-num.  \n",
    "# We standardize these values to a scale from 0 to 100, rather than a more traditional 0 to 1, in order to make them more \n",
    "# closely match the naturally occurring scales in the other variables.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df_income['capital-gain'] = MinMaxScaler(feature_range=(0,100)).fit_transform(df_income['capital-gain'])\n",
    "df_income['capital-loss'] = MinMaxScaler(feature_range=(0,100)).fit_transform(df_income['capital-loss'])\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>2.174022</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39             13      2.174022             0              40   \n",
       "1   50             13      0.000000             0              13   \n",
       "2   38              9      0.000000             0              40   \n",
       "3   53              7      0.000000             0              40   \n",
       "4   28             13      0.000000             0              40   \n",
       "\n",
       "   workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0             0                       0                     0   \n",
       "1             0                       0                     0   \n",
       "2             0                       0                     0   \n",
       "3             0                       0                     0   \n",
       "4             0                       0                     0   \n",
       "\n",
       "   workclass_ Never-worked  workclass_ Private             ...              \\\n",
       "0                        0                   0             ...               \n",
       "1                        0                   0             ...               \n",
       "2                        0                   1             ...               \n",
       "3                        0                   1             ...               \n",
       "4                        0                   1             ...               \n",
       "\n",
       "   native-country_ Portugal  native-country_ Puerto-Rico  \\\n",
       "0                         0                            0   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   native-country_ Scotland  native-country_ South  native-country_ Taiwan  \\\n",
       "0                         0                      0                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         0                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "\n",
       "   native-country_ Thailand  native-country_ Trinadad&Tobago  \\\n",
       "0                         0                                0   \n",
       "1                         0                                0   \n",
       "2                         0                                0   \n",
       "3                         0                                0   \n",
       "4                         0                                0   \n",
       "\n",
       "   native-country_ United-States  native-country_ Vietnam  \\\n",
       "0                              1                        0   \n",
       "1                              1                        0   \n",
       "2                              1                        0   \n",
       "3                              1                        0   \n",
       "4                              0                        0   \n",
       "\n",
       "   native-country_ Yugoslavia  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code drops the target, then gives us one-hot encoding for the categorical variables, rather than a mix of integer values \n",
    "# and descriptive string values.  We will use this newly created \"df_dummies\" variable later on for classification that requires\n",
    "# one-hot encoding to perform well.\n",
    "df_intermediate = df_income.drop('income', axis=1)\n",
    "df_dummies = pd.get_dummies(df_intermediate)\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • [5 points] Describe the final dataset that is used for classification/regression  \n",
    "\n",
    "<font color='blue'>\n",
    "(include a description of any newly formed variables you created). </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dataset we have created consists only of continuous variables (some integers some scaled to floats), categorical variables that are represented as integers, and binary variables that are represented as integers.  For one classification task the response variable will be the \"income\" variable which represents a 0 for income less than 50,000 dollars a year and 1 for income greater than 50,000 dollars a year.  For the other classification task the response variable will be the \"education-num\" variable which is an integer value that represents the years of education attained for a given individual.  \n",
    "  \n",
    "Variables:\n",
    "Age - continuous(integer) - the individual's age in years.  \n",
    "workclass - categorical(integer) - the class of the worker's employment (self-employed, public, private, etc.).  \n",
    "education - categorical(integer) - the level of education obtained (high school, bachelor's degree, master's degree, etc.).  \n",
    "education-num - continuous(integer) - the level of education obtained as represented by number of years of education.  \n",
    "marital-status - categorical(integer) - The current marital status of the individual (married, never married, divorced, etc.).  \n",
    "occupation - categorical(integer) - The type of work the individual is employed in (executive, janitorial, etc.).  \n",
    "relationship - categorical(integer) - What part the individual plays in their current relationship (husband, wife, etc.).  \n",
    "race - categorical(integer) - the individual's race.  \n",
    "sex - categorical(binary) - the individual's gender where 0 is female and 1 is male.  \n",
    "capital-gain - continuous(scaled to float) - the individual's amount of capital gain as measured in US dollars.  \n",
    "capital-loss - continuous(scaled to float) - the individual's amount of capital loss as measured in US dollars.  \n",
    "native-country - categorical(integer) - the native country for that individual (USA, Ecuador, etc.).  \n",
    "income - categorical(binary) - The individuals general income level where 0 is less than 50,000 US dollars of income a year and 1 is more than 50,000 US dollars of income a year.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Modeling and Evaluation (70 points total)  \n",
    "### • [10 points] Choose and explain your evaluation metrics that you will use  \n",
    "\n",
    "<font color='blue'>\n",
    "(i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s)\n",
    "appropriate for analyzing the results of your modeling? Give a detailed explanation\n",
    "backing up any assertions.  \n",
    "</font>\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metric that we will be using for both classification tasks is accuracy.  This is appropriate because what makes these classification task results useful is how accurately they can predict the classification of newly observed individuals.  Furthermore, the intention of this model is to be presented to a wide audience, including non-technical audience members such as legislators, and so a simple evaluation metric of a single number is desireable.\n",
    "\n",
    "While some of the pitfalls of using precision and recall are avoided, including having an overly large confusion matrix, we still feel that they do not provide us with anything significantly more useful than what we already get from just using accuracy.  Specifically, we see the main benefit of using precision and recall as being able to place greater weight, or importance, on focusing on one part of the confusion matrix over others.  An example of this could be with medical treatments where missing a true diagnosis is so much more serious than missing a false diagnosis that it is more desireable to tune a model to place more weight on avoiding false negatives at the expense of allowing more false positives.  In our situation we do not care more or less for one type of error versus the other, therefore using precision and recall would needlessly introduce some small amount of complexity to no real benefit.  \n",
    "  \n",
    "  Finding the area under a POC curve would similarly introduce needless complexity with not much gained.  Explaining an accuracy percentage provides nearly the same information with much less effort expended and much less odds of the audience misunderstanding the explained results of the model.  We will therefore proceed with the evaluation metric of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • [10 points] Choose the method you will use for dividing your data into training and testing splits \n",
    "\n",
    "<font color='blue'>\n",
    "(i.e., are you using Stratified 10-fold cross validation? Why?). Explain why\n",
    "your chosen method is appropriate or use more than one method as appropriate.  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a different training and testing split method for each of our two classification tasks.  For the classification task related to the income variable we will be using stratified 5-fold cross validation, whereas for the classification task related to the marital-status variable we will be using stratified 10-fold cross validation.  \n",
    "  \n",
    "The reason we are using 5 folds for the first classification task is because we are running these tasks on consumer-grade equipment against a 30,000+ size dataset.  Therefore it is desireable to decrease the computing time for our model as much as possible.  We can get away with using fewer folds in this classification task, thus reducing our computing time, because we only have a binary response variable where both of the two response classes are represented well within the data, each having a frequency of at least ~25% of the data as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: (32561,)\n",
      "Number of unique classes: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEcCAYAAAB9K0udAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucVVX9//HXAEqII5oOaZhaqJ8UNS8/TeurpWVFXn9m\nXhOp1PCLl5Qi8pvlJfGaXyzzm1mYaWRlZaakdjGxLL+Ud6VPSRhKKiiIyIignO8fn3Wcw+HMsM/M\n2Wc2M+/n4zEPOHvty+fsObM/Z6299lotpVIJERGRIhrQ2wGIiIh0RklKREQKS0lKREQKS0lKREQK\nS0lKREQKS0lKREQKa1CzD2hmI4ApwPuB14DpwAR3f9HM9gTuBUpAS9rkZXffIG07KG17VFpnKjDJ\n3UuNKBcRkWJpapIyswHALcB8IkkNAb4FXAccAowCHgb2pyNJrazYxUWpbDTQCtwALAYmN6hcREQK\npKWZD/Oa2a7ATGBTd1+Qlr0HuAfYCPgKsJm7H1Nj28HAC8CR7n5bWjYGuNjdN+tpea5vXEREuqXZ\n96SeBEaXE1SVDYHtAe9k252JmteMimUzgOFmNrIB5SIiUjBNbe5z94XAnVWLzwD+4e5zzWx7YJmZ\nPQhsQiSRM939WWAE0O7uSyq2fZZoFtwc2LiH5bMb9DZFRKRBerV3n5l9ATgUOM3MhgJvA9YBPg0c\nA2wB3G5mA4H1gGVVu3g1/Tu4AeUiIlIwTe/dV2ZmZwPnAOPd/c60bBiw1N1XpteHAf8mOlm8wurJ\npPy6vQHlIiJSML2SpMxsCnAKMM7drykvr2qKw93nm9kLRFOfA0PNbKi7L02rbEZ0JZ8HrOhheadK\npVKppaWlq1VERGR1Pb5w9sZzUucB44Gx7n5DxfI9gN8AO7j73LRsC6ANeBx4lKgN7Q3cnjbbB3jO\n3eeY2TNEjahb5V3F3N7ezvz5i3v2xvuITTZp5fnnl6x5xX6gCOdi4MBBDBkypFdjAGhra2XBAn0u\nQOeiUltba4/30ewu6LsQXdAvJR6qrbQQeBB4huhMMQS4Aljs7h9J218BHACMSeXXA1Pc/ZJGlHfm\ngx8bX2pZf4sevfe+YkBLCys1BxlQjHOx8TqL+caFX+zVGEAX5ko6Fx3a2lrXuprUYUT1b2L6Ib0u\nATsSD9leDtxFdOq4mUhYZROJ+0i3EZ0erq1KMD0tr2m9jUZQGvbOut6oSDMMWalOqdK3NbUmtbY6\n+ITJpdKwUb0dhshqNlk5m0vOOrG3w1DtoYLORYdG1KQ0wKyIiBSWkpSIiBSWkpSIiBSWkpSIiBSW\nkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSI\niBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSW\nkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSIiBSWkpSI\niBTWoGYf0MxGAFOA9wOvAdOBCe7+opkNSmVHASVgKjDJ3Utp21zLRUSkWJqapMxsAHALMJ9IUkOA\nbwHXAYcAFwH7A6OBVuAGYDEwOe0i73IRESmQZtekdk4/m7r7AgAzOw24x8zeAowDjnT3malsEnAx\nMNnMBudZ3pR3LyIidWn2PakngdHlBFVlK6JmNaNi2QxguJmNJJJbnuUiIlIwTa1JuftC4M6qxWcA\nTwAjgHZ3X1JR9izQAmwObJxz+eyevTsREWm0pnecqGRmXwAOBQ4AhgPLqlZ5Nf07GFgv53IRESmY\nXktSZnY2cA4w3t3vNLOPsXqyKL9uB17JuVxkrbPuugNpa2vt7TAAChNHEehcNE6vJCkzmwKcAoxz\n92vS4qeBoWY21N2XpmWbEV3F5wErci4XWessX/46CxYsWfOKOWtray1EHEWgc9GhEcm66Q/zmtl5\nwHhgbEWCAniIqNHsXbFsH+A5d5/ThHIRESmYZj8ntQtwFnAp8OvU7bzseeLh2ivNbAzRE+9C4uFb\n3H2ZmeVWLiIixdPs5r7DiN50E9MP6XUJ2DEtGwzcRnRquNbdL6nYPu9yEREpkJZSSSMCrcnBJ0wu\nlYaN6u0wRFazycrZXHLWib0dhu7DVNC56NDW1trS031ogFkRESksJSkRESksJSkRESksJSkRESks\nJSkRESksJSkRESksJSkRESksJSkRESksJSkRESksJSkRESksJSkRESmsTAPMmtn3gOuB37m7BvsT\nEZGmyFqTagF+CjxtZl8zs51zjElERATImKTc/XjgLcDpwJbAvWb2mJl90cy2yjE+ERHpxzLfk3L3\nV939Jnc/HBgO/Bg4G5htZjPM7Oi8ghQRkf6prkkPUzPfkcARwFuBW4Fp6f+XmtmH3X1so4MUEZH+\nKWvHiXOJ5LQNcA8x7fpP3H1xxTqLgG8DYxsfpoiI9EdZa1KHA9cBP3D3uZ2s8xBwUkOiEhERIXvH\niVFE775NysvM7FQzs4p1HnP3aY0PUURE+qtMScrMDiRqSqMrFh8I3G9mH8wjMBERkay9+yYDZ7n7\nBeUF7v5h4L+Ai/MITEREJGuS2hr4RY3ltwDbNS4cERGRDlmT1N+Bg2ssHw38q3HhiIiIdMjau++r\nwI1m9h/ATGKYpF2BQ4ExOcUmIiL9XNbefTcB+wMrgeOIh3lXAvu4+435hSciIv1Z5hEn3P0u4K4c\nYxEREVlF1hEnhhAP6u4OrEM0973B3Y9ofGgiItLfZa1JfYe4/3Q78FJ+4YiIiHTImqQOAQ5z9zvy\nDEZERKRS1i7oS4Anc4xDRERkNVmT1OXARWa2yRrXFBERaZCszX1HADsBz5nZEmB5ZaG7D290YCIi\nIlmT1JV5HNzMpgO3uvtV6fWewL1AiY4ehC+7+wapfBAwBTgqrTMVmOTupUaUi4hIsWRKUu5+XSMP\namYDgG8CHyZm9y0bBTxMPDhcTlIrK8ovSmWjgVbgBmAxMQBuI8pFRKRAMj/Ma2ZHAJ8DtiWGRDoV\neMrdL6/ngGb2duD7wAjgxari7YHH3X1Bje0GA+OAI919Zlo2iRiFfXJPy+t5DyIi0hxZ55MaC1wF\n/BxYNy3+G3CumU2s85h7AbOIRFf9zNX2gHey3c7AEGBGxbIZwHAzG9mAchERKZisvfsmACe7+4XA\n6wDufjXwKeDkeg7o7tPc/SR3r65FQSSpnc3sQTN72symmdmmqWwE0O7uSyrWf5ZoFty8AeUiIlIw\nWZPUSOAvNZbfD2xaY3ndzGwokSzWAT4NHANsAdxuZgOB9YBlVZu9mv4d3IByEREpmKxJyoH9aiw/\ngmj26zF3XwpsCBzs7n919xnAYcAOwPuBV1g9mZRftzegXERECiZrx4mzgJvMbPe0zTgz2xo4EDi8\nUcFUNcXh7vPN7AWiqc6BoWY2NCU0gM2IruTzgBU9LBdZ66y77kDa2lp7OwyAwsRRBDoXjZO1C/qv\nzGwP4PPAo0Q37lnAnu5+fyMCSfv/DbCDu89Ny7YA2oDH03FfAfYmBroF2Ad4zt3nmNkzRI2oW+WN\neA8izbZ8+essWLBkzSvmrK2ttRBxFIHORYdGJOt65pN6DBjb4yN27gHgKWCqmZ1B9MS7ArjT3f8C\nYGbfBa40szGp/ELi4VzcfZmZTe1uuYiIFE/W+aQu6arc3evthl72xkgP7r7CzEYT4wTeRdwvuxk4\no2L9icR9pNuITg/XuvslDSwXEZECyVqT2r3Gdm8HNgK6PX28u7+j6vVcurjH5e6vEg/kjsujXERE\niiXrPal9ay03synAaw2NSEREJMnaBb0zXyce6BUREWm4niap95JGoBAREWm0rB0nZlLRySFpJQab\nvajRQYmIiED2jhO3sWqSKhETH8509982PCoRERGyd5w4J+c4REREVpO1uW9q1h26uzpSiIhIQ2Tt\nONEOHA28J71+lRj4dSwwnLg/Vf4RERFpiKz3pIYB1wLj3f2Ne1Nmdj4w0t2PySM4ERHp37ImqUOB\n3SoTVPJ94KHGhiQiIhKyNvc9A9QadeIQ4F+NC0dERKRD1prU+cTo5PsRs/EOAPYEPkJMTCgiItJw\nmWpS7n49MDqtP4ZITAuBXdz9tvzCExGR/qye+aR+Q0xKKCIi0hSZk5SZHQFMAAzYFTgFeNrdL88p\nNhER6ecyNfeZ2VjgKmISwnXTYgfONbPuTngoIiLSpay9+yYAJ7v7haRRz939amKajpNzik1ERPq5\nrElqJPCXGsvvBzZtXDgiIiIdsiYpB/arsfwI4G+NC0dERKRD1o4TZwE3mdnuaZtxZrY1cCBweF7B\niYhI/5b1OalfAbsDbwIeBfYHlgF7uvst+YUnIiL9WdapOq4CvubuY/MNR0REpEPWe1LHACvzDERE\nRKRa1ntS3wYuM7MLgTnAK5WF7t7e6MBERESyJqlPAhsTU3bUMrAx4YiIiHToNEmZ2Q7A4+6+EvXg\nExGRXtBVTepeYHvgaeArwGHu/mJTohIREaHrJPUq8Ckzuxt4P/A+M1tUa0V3n5FDbCIi0s91laTO\nBS4FzgFKwM87Wa+E7kmJiEgOOu2C7u5XAusBrUALMX5fa42fDfIPU0RE+qMue/e5ewlYamZvB+am\n1yIiIk2RqQu6u/8r70BERESqZR1xQkREpOkyTx+fBzObDtzq7lel14OAKcBRRIeMqcCkcjNj3uUi\nIlIs3UpSZjYY2Alwd3+pG9sPAL4JfBi4taLoImKE9dFEp4wbgMXA5CaVi4hIgWRq7jOzrc3sbjPb\n08zWJ2bpvQ/4l5ntVc8BUyeMu4kE9WLF8sHAOOBMd5/p7r8DJgGnNqNcRESKJ+s9qW8ALwFPAmOB\nzYBtgf8BLq/zmHsBs4Bd0z7LdgGGAJUPBs8AhpvZSGDnnMtFRKRgsiapvYEz3P1Z4GDgFnd/ArgG\neFc9B3T3ae5+Uo0hlt4KtLv7koplzxLPaG0OjMi5XERECiZrkloGvMnMNgD2AX6Vlm8O1BwqqRvW\nS8ep9Gr6d3ATykVEpGCydpy4A/gesBRoB6ab2WiiGfBnDYrlFVZPFuXX7U0oFxGRgsmapD4DfBXY\nCjjE3Zea2bZEgvpSg2J5GhhqZkPdfWlathnRVXwesCLncpG1zrrrDqStrbW3wwAoTBxFoHPROFlH\nnHgZ+GzV4mnuvqCBsTxE1Gj2Bm5Py/YBnnP3OWb2TJ7lDXwfIk2zfPnrLFiwZM0r5qytrbUQcRSB\nzkWHRiTrTEnKzNqAy4iefI8D04H9zGwOcJC7z+ppIO6+zMymAlea2RiiJ96FxMO3uZeLiEjxZG3u\n+yawJbAE+ATwbuI5p2OBrxMPyHZH9UgPE4n7RLcRnRqudfdLmlguIiIF0lIqrXlEoDTZ4d7u/qiZ\n/YLoyn20mW0NPOju6+cdaG86+ITJpdKwUb0dhshqNlk5m0vOOrG3w1ATVwWdiw5tba0tPd1H1i7o\nLcCradSGD9BxT2cY6hknIiI5ydrcNwO4ghghYgDwSzPbneiCfmdOsYmISD+XtSb1GWA58E7geHdf\nCBwEzAVOyyk2ERHp57J2QX8GOLRq2ZdziUhERCTJ2gW9hRizbwdgYFrcQvSU283dP5xPeCIi0p9l\nvSd1OXAKMXr5KOLB2y2BDYHv5hOaiIj0d1nvSR0NfNLddwLmEDPbjiAmLFTvPhERyUXWJPVmOuZh\negTYw92XAedSda9KRESkUbImqXnAFun/TsccUouBtkYHJSIiAtnvSU0DbjCzscS4fTeb2WPAAcR9\nKhERkYbLWpP6MnA1sIG7lx/s/TrR2298TrGJiEg/l/U5qdeJEcPLr88l7keJiIjkptMkZWaZRwd3\n94mNCUdERKRDVzWp3TPuY83DqItILlauXMns2f/o7TBYtGh9Fi58ubfDKASdiw5tbbv2eB+dJil3\n37fHexeRXC1Z/AKnX3oL6w0b3tuhiKyiffF87vtpjkkKwMzWBY4HfuLuL1YsPx1YBkx19xU9jkJE\num29YcNZf6MRvR2GSC467d1nZhsAdxPTcWxXVbwF8N/Ab8ysT094KCIivaerLuhfAtYHtnH3P1UW\nuPsEYCdiaKQv5heeiIj0Z10lqcOBCe7+VK1Cd38CmAh8PI/AREREukpSmxJDIHXlfqI2JSIi0nBd\nJamngG3WsP3WwLONC0dERKRDV0nqJuBcMxtcqzAtPwe4LYe4REREuuyCfiExDcdfzezrwExi1PON\ngD2AU9P25+cdpIiI9E+d1qTc/WVgL+Ae4FLgL8A/iGR1PvAbYC93X9CEOEVEpB/q8mFed38JODk9\nvPsOohb1PDDb3Vc2IT4REenHso6Cvhz4W86xiIiIrCLrfFIiIiJNpyQlIiKFpSQlIiKFpSQlIiKF\npSQlIiKFpSQlIiKFpSQlIiKFlek5qWYysz2Be4ES0JIWv+zuG5jZIGAKcFQqnwpMcvdS2rZH5SIi\nUiyFS1LAKOBhYH86klR5dIuL0vLRQCtwAzGe4OQGlYuISIEUMUltDzxePSZgGnV9HHCku89MyyYB\nFwOTe1relHcmIiJ1KeI9qe2pPdnizsAQYEbFshnAcDMb2YByEREpmKLWpJaZ2YPAJkQiOZOYAbjd\n3ZdUrPss0SS4ObBxD8tn5/N2RESkuwpVkzKzoUTCWAf4NHAMsAVwB7AesKxqk1fTv4MbUC4iIgVT\nqJqUuy81sw2BpeWpQMzsMGAekWCqk0n5dTvwSg/LRdY666wzAF7v7ShE8lOomhSAuy+pnKvK3ecD\nC4GRwNBU2yrbjOhKPg94uoflImudFSs0rZv0bYVKUma2h5m9ZGZbVCzbgrg3dS9R49m7YpN9gOfc\nfQ7wUA/LRUSkYArV3Ac8ADwFTDWzM4jeeFcAv3b3e8xsKnClmY1JZRcSD+fi7st6Ui4iIsVTqCTl\n7ivMbDRwOXAXUdO7GTgjrTKRuI90G9Hp4Vp3v6RiFz0tFxGRAmkplTQi0JocfMLkUmnYqN4OQ2Q1\n67zwZxYNeBvrbzSit0MRWcXLi+Zx19T/bFnzml0r1D0pERGRSkpSIiJSWEpSIiJSWEpSIiJSWEpS\nIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJS\nWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpS\nIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWEpSIiJSWIN6O4Bm\nM7NBwBTgKKAETAUmuXupVwMTEZHV9LskBVwE7A+MBlqBG4DFwOTeDEpERFbXr5r7zGwwMA44091n\nuvvvgEnAqb0bmYiI1NKvkhSwMzAEmFGxbAYw3MxG9k5IIiLSmf6WpEYA7e6+pGLZs0ALsHnvhCQi\nIp3pb0lqPWBZ1bJX07+DmxyLiIisQX/rOPEKqyej8uv2zjZ6bcm/aXltZW5BrU0GDhrA6zoXQDHO\nxevLXqR9hb5fSfG0L57fkP30tyT1NDDUzIa6+9K0bDOiK/q8zjaa/qMrW5oRnIiIrKq/Nfc9RNSY\n9q5Ytg/wnLvP6Z2QRESkMy2lUv96htXMrgAOAMYQPf2uB6a4+yW9GpiIiKymvzX3AUwk7kPdRnSa\nuFYJSkSkmPpdTUpERNYe/e2elIiIrEWUpEREpLD64z2p1dQzMnpfH0W9znMxIq37fuA1YDowwd1f\nbFrAOeru79rMLgCOcfe35x9lc9T5uRgAXACMBd4E3A6Md/eFTQs4R3Wei9a07kFp0XRi7NA+cS4q\nmdl04FZ3v6qT8m79PSlJhXpGRu/ro6hnen/pQnQLMJ9IUkOAbwHXAYc0L9xc1f27NrPdgM8Tz+T1\nJfX+jRxLXIwWAdcCVwMfb0qk+avnXFwFbA18kGi5uib9fKwpkTZBuhZ8E/gwcGsXq3br2tnvm/vq\nGRm9r4+iXuf72zn9jHH3x9z9L8BpwIFmtkHTgs5Jd37XZrYOcUH+Y3OibI46/0Za0/KT3f1ud38Y\nmACMMrOBzYw7D934XBxEPOLysLs/CFxOJKw+wczeDtxNJKhOW1B6cu3s90mK+kZG7+ujqNfz/p4E\nRrv7ghr72TCf8JqqO7/rrwD/AG7KObZmq+dc7A28TjziAYC7/97dt3f313OPNH/1fi6eB441sw3S\nl7djgL/kH2bT7AXMAnYFXupivW5fO9Xct+aR0Wd3c921Ueb3l9rU76za/gzgCXefm3egTVDX7zo1\n850A7ETfadYqq+dcbA3MBQ4ys68AbcQ9qTPdvauL2Nqi3mvASUSz1qL0ejbwH3kH2SzuPg2YBmBm\nXa3a7WunalL1jYze10dR7/b7M7MvAIfSR5o+qeNcpGa+qcDn3L0xo2oWSz2fi1bignQ28FngaOJb\n9rQ8A2yiev9G3gn8jbhvuy9xD+YHeQVXYN2+tihJ1TcyerdGUV+LdOv9mdnZxM3PU929una1tqrn\nXHwZeMrdb0iv+9qAxPWcixXA+sS9yrvd/R7gU8BHzewd+YbZFJnPRXq/Xwc+7e73uPsMosPEfma2\nT+6RFku3r51KUhUjo1cs62xk9HrWXRvV/f7MbApxL2acu38r/xCbpp5zcSxx4VliZkuAy4Atzewl\nM3tvc8LNVT3n4t/p31kVy/6W/t0yn/Caqp5zsRvRxPXG4NWpKfx5oC8k7Hp0+9qpJFXfyOh9fRT1\nut6fmZ0HjAfGuvs1zQmxaeo5F+8DdgDelX4uJP7w3kXfuElez7ko92zctWLZDsTF6J+5Rdg89ZyL\necSFeYvyAjN7C7Axa//963p1+9qpsfvoemR0M9sIwN0XrWnd3oi90bKeCzPbBZgJXEo8oFfp+b7Q\nk6uez0XVduOJh5r7zLflOv9GfgRsR3QaWAF8G5jn7gf3RuyNVsffyADgT8S9l88SifoyYIi7v6dX\ngs+Rmc0BLi0/zNuoa6d694WuRkb/GfHh2i/Dun1B1nNxGHHvZWL6Ib0uATsCjzcx5rzU87no6+o5\nF8cTF+NbgYHAzcDpTY02X5nOhbuvNLMDga+ldVuAO4hesH1RdY2nIddO1aRERKSwdE9KREQKS0lK\nREQKS0lKREQKS0lKREQKS0lKREQKS0lKREQKS0lKREQKSw/zCgBmtj7wReBw4G3EMPo3AV8tT7Fg\nZncBM919Yqc7KhAz2xKYA+zg7rk8XJxGFfgjcJy7P5HHMfq6NKXHAe6+R3p9KPE5W+N4mGZ2PHCZ\nu7d147g7Ahu7++/zWH8N+7oZ+G93v7un++rrVJMS0mRs9xHTCYwnhrQZR0zzfIeZrdt70fVY3k+r\nnw48qATVI5cSM7uSxrn7GTCsju27+zv+BbB9jut35UvAVWamisIa6AQJwMV0DOVSnuPlX2b2UWKm\n2eOBtXUA2dymzUjJexKR3KWb3L2djukaBpD/F4uyej8bDfssufujZvYMMd/W9Y3ab1+kJNXPpQvt\nMcDnKxIUAO7+lJnty6rTLpS3Gwicl7YdASwEfkjMwFoys82Aq4mRjkvAr4Hx7r4gNS1eTXx7fhNw\nDzEX1Wq1ETN7kmjOubJi2S+Bue4+3sx2J0YdfzfxeX4ION3d76uxr5XAge4+Pb1+H3AXsL67t6e4\nLifm/CkBv0v7eqaT03cUsMjd3zg/aSrsy4iR0VcStYIz3f3liubHjwNfBbYiRkn/lLv/I22/DTEH\n0T7AfODHwNnuvrzG+ynv7xjgAmIW3DuJaVOeT+u8BfgG8BHgZWLctAnu/lLF9mcDZwJ/cvcDq47x\nPuBGYoDUy4ANge8Rgwp/F9gDeAT4RMV7OJYYp82IMdruAk5Mv/vjgdOIsR0PIr4grUtHc98/07l/\nxMzOdffzutpfJ7+XyvjPBk5M52YWcJa7356arrcEvmFmh7v7fp18lk5z9/+tXh/4JFVNydVNj2Z2\nEvB5ovn8n8CF7l6ZkH5O1MSVpLqg5j55BzFJ3cxahe7+J3d/sUbRRGIepeOIKcM/B5wClEe6/h/i\nD313Ynj+LYmLHMQF2ogayM7Aa8QFr5YfAkeUX5jZMGB/4AcpqUwH7icGtX03cSGuZ16rym/t1wAj\ngQ8SSWIlcHu671TLAcTU6OXYNgT+QFxI3wv8f2Kq8Or3djbwaeD/AZsAl6TtBxMDkDoxzcdxRCKv\nHmW+2mTgM0Ri3IpIbGU/A14nzs2BxO/7xqrtRxPJ5vOd7H/jFO+HiAv+eOJLx9fSdoOJiztmthcx\nS/HFwDbAIcAuwFkV+9uF+FKzK6tfoPcgaizvAy7LuL+a0r2tzxEtAUYk6B+nz81hxBxHXwQO6+Kz\ndHXa3Srrp2W1anyldOxdgKuIv5NtgCuAa9OXmLLbgV3MrO77af2JkpRslP5dXOd2jxHzSP3B3eem\nWWlnEXMHQVwsXyJqPI8SzRqXV5QtTWVPEBe+L3RynGnAe1LNDOIC8Yy730tMSX0xMMndn3T3h4nk\nuEPtXXUuzaJ6JHCsuz+Qvh0fD7yddL+kht2J81D2CeJvaoy7z0qz0o4FPl51cfqqu9/r7o8RF7Ld\n0/JjgFfd/bPu/oS7/wE4GTgpXUQ78yV3/427P0Akk/dZ2Je44B6X4rmfSHwfMbPtKraf4u6zK2uE\nVQYSNe1Z7n4jUcP7ubv/Mv1ubwBGpXWXASe4+zR3fyp1MvgFq/5OSsD57v5Pd3+66ljl2tHC1AyY\nZX+d2QpYTsyaPJeo+R8GrEjTR7wOvJy+hHX5WaqxPnTd/Lcl8SXn6RR3ueWgsvb3zxTf7jW2l0TN\nffI88ce20ZpWrOTut5jZPmZ2EfEtdUfigj4wrXIBcB3wgpn9lpiuoTy9+teIC818M5sB3EI0IdU6\nziNm9jjRRPZ1olZ1Yyqbb2bfAcab2buAbYlv59358lW+aP/dzCovPkOAdwK/qrHNW4jzV7mPB6ua\n5mYSF6JRRPMRQGWz5kvAOun/2wNbp9l9y8qxbAM8UCOGElF7A8DdHzKz5cTFdVNgKLDIzCq3WZne\n0/3pdZZGzck/AAAFHElEQVQJOyvXeaXG68Hp+A+kGYq/lN7PdimWeyrWX1pujlyTjPvrzA+IOa3+\nbmYPEFOHTK1u1k7HaeRnCaKWdB9wn5n9jajFfa/cUzYds2Rmi4Dh3TxGv6CalMwmml72qFVoZl8z\ns9XmAkrdhm8mktJPgY/ScRHG3X8CbE40DbUTzR3TU9k9RDv9cUQTyjnAn1JzVy3TgCPM7M3AB9Jr\nUu3qEaKJ8XHim/KJmd/5ql/SBhHNdO+q+tkWuLaT7Vey6t/Qsk7Wa6EjeUMkrerycgz3AjtVHH+n\nFENXXehfK/8nJdgBxLf+QcCTVfsrv6c7K7Z/pYt9r3aMZGWtlczsg8TvZCRwN9EMeVXVap2dp+7u\nr6Z0z2oU0Xx7F1FTfdDMVquFdeOzVKup743Pk7svc/e9gfcQfx/7AzPN7ANV2wwkflfSCdWk+rk0\nMds04FQzW+VbppltTTQ31ZqkbQJxU/l7ad03EU0cLen1ecAv3f064Lp0sbkjtb8fA/w9JbKfpOP8\nnbiY1ro3Ng04n2jKcnd/JC0/mmi62b8i5q6e4VoOtFa8rmyCm0XcwG9NTT2Y2dB07AuA/62xv2eJ\ne0qV+/iEmQ2uOI97EH9nWZ7TmkU0Oc4r18bMbE/ivsbxRBKt1gLsBvw7vd6Njpv+7cBbiSaqBWl/\nWxIdKU6nk0TTQ6cBP3L3T5YXmNk5ZO8ZV33x7/b+zGw0sK27XwH8zsy+QHwpGw08WnWsLJ+lyvXL\nXzRqfp7S7+0j7n4O8GfgbDP7A9Hc+Nu0TgvwZuJzJJ1QkhKAc4neX79NF4AniKaOS4ikMbXGNvOA\nA8zsHuKZlq8QPb/KtaF3Ah+ymEp9MdHJYk7q4TWCSIqfJGpSn0rreK3g3H2umf2Z6HAwuSqGt5jZ\nAcRFZ1/gv+CNXovVZgL/aWYPEj0SJ1Qc4++p1+D1KeYXiM4Au1Gjd2PyV6JmUvaDFOP3U5LemPjW\n/2t395QgunJDxfbnE+f1O8AT7r6ki+0uM7OFxIXzauLLwZzUM/Ix4Edm9jkiKV1JdJR5EthiDfF0\nxzzintguRMeDscRn688Zt385/buzmT3dw/21ABeZ2XNEDXVPoom2/IXjZWC79MWpy89S+tJQuf5z\nwFPABDObRHwOxlYceylwlpm9QDRnG9Fc+e2Kdcr38e5HOqXmPsHdXyB6o91PXOQeAy4CfkR0DV6R\nVq38JjmWuAf1MNGDbA7Ri223VD6OSHa/Ah4kmv4OSmVfSstvTMfaF/hoZXt9DT8g7q/8sGLZj4ke\nedcSNYcTgRNSnOU4KmM+hUiiDxIPkFZ31hhDJLKfExfBNwEf7CJB3Eb0QgPA3V8hbo4PIy6EPwF+\nT3RpL+v0GaDUUeBDRLK/L8XxR6JDRlemEuflTuJ3eGzaX4lovnqB6E7/O6LG9dFU1mU8Xehqm68Q\ntZW7iXtl2xNfBrbv5IvDKtx9IZGYv0M0A3+Z6GBQ9/7SowYTiFq4E71KT/GOUR6uIM7t7e7+o3TM\nrj5LleuXiG7o2xGf4dOJnn/lYz9CtBicRHzJuQa41N2/XxHiPsB96e9POqHp40W6ycyGEMl5dOpZ\n1+zjb0lcwHf0nIZ9kvyY2R+Bb7r7tN6OpchUkxLpplRzupToHNJbchtRQ/KTmi/bWP2ZNamiJCXS\nM1OAHdNIEb1BTSFrp/OAk9w9j84rfYqa+0REpLBUkxIRkcJSkhIRkcJSkhIRkcJSkhIRkcJSkhIR\nkcJSkhIRkcL6P6b6AhjlARxYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaf976a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code shows a graphical representation of the class value distribution for the income variable.\n",
    "# This code was built upon the example provided in the \"Grand Poobah Classification Notebook\" from course materials\n",
    "\n",
    "print( 'Size of the dataset:', df_income['income'].shape)\n",
    "print( 'Number of unique classes:', len(df_income['income'].unique()))\n",
    "\n",
    "plt.hist(df_income['income'], bins=len(df_income['income'].unique()))\n",
    "plt.xlabel('Class value (one per marital status)')\n",
    "plt.ylabel('Class frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, while both classes have  large frequency we still see that those with less than 50,000 USD of income a year number about three times as many individuals as those who make greater than 50,000 USD of income a year.  As such we feel that stratifying the k-fold cross validation will help prevent against any training/test splits that could have fewer than desired \"1\" classifications due to random chance.  \n",
    "  \n",
    "As for the marital-status classification task, we absolutely must stratify the cross validation because there are more classes and a far greater discrepancy in the relative frequency of those classes.  In fact, there are some classes with over 10,000 individuals classified by them whereas other classes describe almost no one.  Furthermore we must use 10 folds rather than 5 because of the small class frequency for some of these class values.  You can see more graphical details on the class frequency distribution below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: (32561,)\n",
      "Number of unique classes: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEcCAYAAABqCdtUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb7c96d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code shows a graphical representation to the one above, this time for the marital-status variable.\n",
    "# This code was built upon the example provided in the \"Grand Poobah Classification Notebook\" from course materials\n",
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "print( 'Size of the dataset:', df_income['marital-status'].shape)\n",
    "print( 'Number of unique classes:', len(df_income['marital-status'].unique()))\n",
    "\n",
    "maritalplot = encoder.fit_transform(df_income['marital-status'])\n",
    "\n",
    "plt.hist(maritalplot, bins=7)\n",
    "plt.xlabel('Class value (one per marital status)')\n",
    "plt.ylabel('Class frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • [20 points] Create three different classification/regression models \n",
    "(e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or\n",
    "logistic regression). Adjust parameters as appropriate to increase generalization\n",
    "performance using your chosen metric.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we set the one-hot encoded \"dummy\" variables as the X and the original target variable (where 0 is <50K and 1 is >=50K) will\n",
    "# become our y.  We also initialize a y_hat variable.\n",
    "X = df_dummies\n",
    "y = np.array(target)\n",
    "y_hat = np.zeros(len(target)) \n",
    "\n",
    "# This creates our K fold model with 5 folds.\n",
    "cv = StratifiedKFold(y, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy when using  1  neighbors:  0.800558950892\n",
      "KNN accuracy when using  2  neighbors:  0.825312490403\n",
      "KNN accuracy when using  3  neighbors:  0.821627099905\n",
      "KNN accuracy when using  4  neighbors:  0.832713982986\n",
      "KNN accuracy when using  5  neighbors:  0.830564171862\n",
      "KNN accuracy when using  6  neighbors:  0.836061546021\n",
      "KNN accuracy when using  7  neighbors:  0.834310985535\n",
      "KNN accuracy when using  8  neighbors:  0.836890758883\n",
      "KNN accuracy when using  9  neighbors:  0.835785141734\n"
     ]
    }
   ],
   "source": [
    "# The following code section was built referencing the section 06 Classification notebook from our class materials.\n",
    "\n",
    "# This code will fit a K Nearest Neighbors classifier with 4 neighbors.  As mentioned before we will do 5 fold cross validation\n",
    "# for classifiers run against the income target variable for the purpose of sacrificing a little bit of accuracy for a lot of \n",
    "# speed in running the models.\n",
    "\n",
    "# This code iterates through the classifier task trying between 1 and 9 neighbors in the KNN. Eventually it finds that the \n",
    "# greatest accuracy is to be found when using 8 neighbors, which results in 83.69% accuracy as seen in the code output below.\n",
    "for i in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    for train, test in cv:\n",
    "        clf.fit(X.iloc[train],y[train])\n",
    "        y_hat[test] = clf.predict(X.iloc[test])\n",
    "    total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "    print('KNN accuracy when using ', i, \" neighbors: \", total_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for KNN on Income target:  \n",
    "As seen in the code output above, the very best accuracy we obtained from a KNN classifier for the income target was 83.69%, and we obtained that accuracy when using the 8 nearest neighbors in our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained from using a depth of  10  and  50  estimators is:  0.856822579159\n",
      "The accuracy obtained from using a depth of  20  and  50  estimators is:  0.861705721569\n",
      "The accuracy obtained from using a depth of  30  and  50  estimators is:  0.856576886459\n",
      "The accuracy obtained from using a depth of  40  and  50  estimators is:  0.848714720064\n",
      "The accuracy obtained from using a depth of  50  and  50  estimators is:  0.84656490894\n",
      "The accuracy obtained from using a depth of  10  and  100  estimators is:  0.856945425509\n",
      "The accuracy obtained from using a depth of  20  and  100  estimators is:  0.863333435705\n",
      "The accuracy obtained from using a depth of  30  and  100  estimators is:  0.855532692485\n",
      "The accuracy obtained from using a depth of  40  and  100  estimators is:  0.850311722613\n",
      "The accuracy obtained from using a depth of  50  and  100  estimators is:  0.847025582752\n",
      "The accuracy obtained from using a depth of  10  and  150  estimators is:  0.857590368846\n",
      "The accuracy obtained from using a depth of  20  and  150  estimators is:  0.862749915543\n",
      "The accuracy obtained from using a depth of  30  and  150  estimators is:  0.857037560271\n",
      "The accuracy obtained from using a depth of  40  and  150  estimators is:  0.849144682289\n",
      "The accuracy obtained from using a depth of  50  and  150  estimators is:  0.848039065139\n"
     ]
    }
   ],
   "source": [
    "# The following code section was built referencing the section 06 Classification notebook from our class materials.\n",
    "\n",
    "# This section of code builds a random forest classifier, and tries it on a variety of depths and number of estimators to find\n",
    "# the very best configuration for highest accuracy score.\n",
    "\n",
    "depths = [10, 20, 30, 40, 50]\n",
    "estimators = [50, 100, 150]\n",
    "\n",
    "for estimator in estimators:\n",
    "    for depth in depths:\n",
    "        clf = RandomForestClassifier(max_depth=depth, n_estimators=estimator, n_jobs=-1, oob_score=True)\n",
    "        for train, test in cv:\n",
    "            clf.fit(X.iloc[train],y[train])\n",
    "            y_hat[test] = clf.predict(X.iloc[test])\n",
    "        total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "        print('The accuracy obtained from using a depth of ', depth, ' and ', estimator, ' estimators is: ', total_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Random Forest on Income target:  \n",
    "As seen in the code output above, the highest accuracy we obtained from a random forests classifier was 86.37%, and that was obtained from a classifier with a tree depth of 20 and 150 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the penalty option of  l1  and a C Value of  0.05 The accuracy obtained is:  0.849605356101\n",
      "For the penalty option of  l1  and a C Value of  0.1 The accuracy obtained is:  0.849728202451\n",
      "For the penalty option of  l1  and a C Value of  0.15 The accuracy obtained is:  0.8508338196\n",
      "For the penalty option of  l1  and a C Value of  0.25 The accuracy obtained is:  0.850925954363\n",
      "For the penalty option of  l1  and a C Value of  0.5 The accuracy obtained is:  0.851417339762\n",
      "For the penalty option of  l1  and a C Value of  0.75 The accuracy obtained is:  0.851325205\n",
      "For the penalty option of  l2  and a C Value of  0.05 The accuracy obtained is:  0.851540186112\n",
      "For the penalty option of  l2  and a C Value of  0.1 The accuracy obtained is:  0.850803108013\n",
      "For the penalty option of  l2  and a C Value of  0.15 The accuracy obtained is:  0.850987377538\n",
      "For the penalty option of  l2  and a C Value of  0.25 The accuracy obtained is:  0.851110223887\n",
      "For the penalty option of  l2  and a C Value of  0.5 The accuracy obtained is:  0.851294493412\n",
      "For the penalty option of  l2  and a C Value of  0.75 The accuracy obtained is:  0.851263781825\n"
     ]
    }
   ],
   "source": [
    "# This code section was built referencing the section 04 notebook from class materials.\n",
    "\n",
    "# This code builds a logistic regression classifier, then runs it for both the \"l1\" and \"l2\" penalty setting, cycling through\n",
    "# a number of C Values for each.  This allows us to then determine the best tuned configuration settings for maximum accuracy.\n",
    "\n",
    "penalties = ['l1','l2']\n",
    "CValues = [0.05,0.10,0.15,0.25,0.5,0.75]\n",
    "\n",
    "for penalty in penalties:\n",
    "    for CValue in CValues:\n",
    "        clf = LogisticRegression(penalty=penalty, C=CValue)\n",
    "        for train, test in cv:\n",
    "            clf.fit(X.iloc[train],y[train]) \n",
    "            y_hat[test] = clf.predict(X.iloc[test])\n",
    "        total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "        print('For the penalty option of ', penalty, ' and a C Value of ', CValue, 'The accuracy obtained is: ', total_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Logistic Regression on Income target:  \n",
    "As seen in the code output above, the highest accuracy we obtained from a logistic regression classifier was 85.15%, and that was obtained from a classifier using the l2 penalty option and a C Value of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This code section was built referencing the section 04 notebook from class materials.\n",
    "\n",
    "# This code builds an SVM classifier, and runs looks to test that classifier with three C Values for\n",
    "# each of three different kernel options to find out what settings we should tune for to see the very highest accuracy.\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "CValues = [0.25,0.5,0.75]\n",
    "\n",
    "for kernel in kernels:\n",
    "    for CValue in CValues:\n",
    "        clf = SVC(C=CValue, kernel=kernel, degree=3, gamma='auto') \n",
    "        for train, test in cv:\n",
    "            clf.fit(X.iloc[train], y[train]) \n",
    "            y_hat[test] = clf.predict(X.iloc[test])\n",
    "        total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "        print('For the SVM kernel ', kernel, \" and the C Value of \", CValue, \" the accuracy obtained is: \", total_accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6125969b67b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0my_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bear\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This code is for testing the SVM classifier, which seems to have a harder time running on my equipment compared\n",
    "# to the other classifiers\n",
    "\n",
    "clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto')\n",
    "for train, test in cv:\n",
    "    clf.fit(X.iloc[train], y[train]) \n",
    "    y_hat[test] = clf.predict(X.iloc[test])\n",
    "    \n",
    "total_acuracy = mt.accuracy_score(y, y_hat)\n",
    "print('accuracy', total_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for SVM on Income target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we set up a new target variable \"maritaltarget\" that includes the integer classification of the marital statuses included\n",
    "# in the data.  We then drop the marital-status column from the income dataset, and set our X as the newly formed dummy variable\n",
    "# dataset for the classification of the marriage status target variable.\n",
    "\n",
    "maritaltarget = maritalplot\n",
    "df_intermediateMarriage = df_income.drop('marital-status', axis=1)\n",
    "df_dummiesMarriage = pd.get_dummies(df_intermediateMarriage)\n",
    "\n",
    "#Now that we have newly formed datasets targeting the marital-status classification we will re-set our X, y, and y_hat variables.\n",
    "X = df_dummiesMarriage\n",
    "y = np.array(maritaltarget)\n",
    "y_hat = np.zeros(len(maritaltarget)) \n",
    "\n",
    "# This recreates our K fold model, only now with 10 folds rather than 5.\n",
    "cv = StratifiedKFold(y, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy when using  1  neighbors:  0.717391971991\n",
      "KNN accuracy when using  2  neighbors:  0.705291606523\n",
      "KNN accuracy when using  3  neighbors:  0.739227910691\n",
      "KNN accuracy when using  4  neighbors:  0.739565738153\n",
      "KNN accuracy when using  5  neighbors:  0.743404686588\n",
      "KNN accuracy when using  6  neighbors:  0.744663861675\n",
      "KNN accuracy when using  7  neighbors:  0.745370228187\n",
      "KNN accuracy when using  8  neighbors:  0.744878842787\n",
      "KNN accuracy when using  9  neighbors:  0.744940265962\n"
     ]
    }
   ],
   "source": [
    "# The following code section was built referencing the section 06 Classification notebook from our class materials.\n",
    "\n",
    "# This code repeats the previous KNN classification task, only this time it will give us the accuracy of the classification for\n",
    "# the marital status target variable because we have changed our X and y variables.\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    for train, test in cv:\n",
    "        clf.fit(X.iloc[train],y[train])\n",
    "        y_hat[test] = clf.predict(X.iloc[test])\n",
    "    total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "    print('KNN accuracy when using ', i, \" neighbors: \", total_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for KNN on Marital Status target:  \n",
    "The best accuracy recorded for the KNN on the Marital Status target was 74.49%, which we obtained when using 9 neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained from using a depth of  10  and  50  estimators is:  0.831884770124\n",
      "The accuracy obtained from using a depth of  20  and  50  estimators is:  0.840207610331\n",
      "The accuracy obtained from using a depth of  30  and  50  estimators is:  0.83010349805\n",
      "The accuracy obtained from using a depth of  40  and  50  estimators is:  0.823807622616\n",
      "The accuracy obtained from using a depth of  50  and  50  estimators is:  0.822916986579\n",
      "The accuracy obtained from using a depth of  10  and  100  estimators is:  0.832314732349\n",
      "The accuracy obtained from using a depth of  20  and  100  estimators is:  0.840576149381\n",
      "The accuracy obtained from using a depth of  30  and  100  estimators is:  0.82985780535\n",
      "The accuracy obtained from using a depth of  40  and  100  estimators is:  0.824237584841\n",
      "The accuracy obtained from using a depth of  50  and  100  estimators is:  0.824513989128\n",
      "The accuracy obtained from using a depth of  10  and  150  estimators is:  0.832222597586\n",
      "The accuracy obtained from using a depth of  20  and  150  estimators is:  0.841251804306\n",
      "The accuracy obtained from using a depth of  30  and  150  estimators is:  0.830809864562\n",
      "The accuracy obtained from using a depth of  40  and  150  estimators is:  0.824145450078\n",
      "The accuracy obtained from using a depth of  50  and  150  estimators is:  0.825005374528\n"
     ]
    }
   ],
   "source": [
    "# The following code section was built referencing the section 06 Classification notebook from our class materials.\n",
    "\n",
    "# This code repeats the previous Random Forest classification task, only this time it will give us the accuracy of the classification for\n",
    "# the marital status target variable because we have changed our X and y variables.\n",
    "\n",
    "depths = [10, 20, 30, 40, 50]\n",
    "estimators = [50, 100, 150]\n",
    "\n",
    "for estimator in estimators:\n",
    "    for depth in depths:\n",
    "        clf = RandomForestClassifier(max_depth=depth, n_estimators=estimator, n_jobs=-1, oob_score=True)\n",
    "        for train, test in cv:\n",
    "            clf.fit(X.iloc[train],y[train])\n",
    "            y_hat[test] = clf.predict(X.iloc[test])\n",
    "        total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "        print('The accuracy obtained from using a depth of ', depth, ' and ', estimator, ' estimators is: ', total_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Random Forest on Marital Status target:  \n",
    "The best accuracy we saw from the random forest classifier was 84.13%, which we saw when using a depth of 20 and 150 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the penalty option of  l1  and a C Value of  0.05 The accuracy obtained is:  0.83864131937\n",
      "For the penalty option of  l1  and a C Value of  0.1 The accuracy obtained is:  0.839040570007\n",
      "For the penalty option of  l1  and a C Value of  0.15 The accuracy obtained is:  0.838794877307\n",
      "For the penalty option of  l1  and a C Value of  0.25 The accuracy obtained is:  0.83888701207\n",
      "For the penalty option of  l1  and a C Value of  0.5 The accuracy obtained is:  0.839194127944\n",
      "For the penalty option of  l1  and a C Value of  0.75 The accuracy obtained is:  0.839409109057\n",
      "For the penalty option of  l2  and a C Value of  0.05 The accuracy obtained is:  0.838794877307\n",
      "For the penalty option of  l2  and a C Value of  0.1 The accuracy obtained is:  0.838733454132\n",
      "For the penalty option of  l2  and a C Value of  0.15 The accuracy obtained is:  0.83900985842\n",
      "For the penalty option of  l2  and a C Value of  0.25 The accuracy obtained is:  0.839194127944\n",
      "For the penalty option of  l2  and a C Value of  0.5 The accuracy obtained is:  0.839593378582\n",
      "For the penalty option of  l2  and a C Value of  0.75 The accuracy obtained is:  0.839409109057\n"
     ]
    }
   ],
   "source": [
    "# This code section was built referencing the section 04 notebook from class materials.\n",
    "\n",
    "# This code repeats the previous Logistic Regression classification task, only this time it will give us the accuracy of the classification for\n",
    "# the marital status target variable because we have changed our X and y variables.\n",
    "\n",
    "penalties = ['l1','l2']\n",
    "CValues = [0.05,0.10,0.15,0.25,0.5,0.75]\n",
    "\n",
    "for penalty in penalties:\n",
    "    for CValue in CValues:\n",
    "        clf = LogisticRegression(penalty=penalty, C=CValue)\n",
    "        for train, test in cv:\n",
    "            clf.fit(X.iloc[train],y[train]) \n",
    "            y_hat[test] = clf.predict(X.iloc[test])\n",
    "        total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "        print('For the penalty option of ', penalty, ' and a C Value of ', CValue, 'The accuracy obtained is: ', total_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Logistic Regression on Marital Status target:  \n",
    "The best accuracy we saw from the Logistic Regression classifier was 84.00%, which we saw when using the penalty option \"l2\" and a C value of 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code section was built referencing the section 04 notebook from class materials.\n",
    "\n",
    "# This code repeats the previous SVM classification task, only this time it will give us the accuracy of the \n",
    "# classification for the marital status target variable because we have changed our X and y variables.\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "CValues = [0.25,0.5,0.75]\n",
    "\n",
    "for kernel in kernels:\n",
    "    for CValue in CValues:\n",
    "        clf = SVC(C=CValue, kernel=kernel, degree=3, gamma='auto') \n",
    "        for train, test in cv:\n",
    "            clf.fit(X.iloc[train], y[train]) \n",
    "            y_hat[test] = clf.predict(X.iloc[test])\n",
    "        total_accuracy = mt.accuracy_score(y, y_hat)\n",
    "        print('For the SVM kernel ', kernel, \" and the C Value of \", CValue, \" the accuracy obtained is: \", total_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for SVM on Marital Status target:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • [10 points] Analyze the results using your chosen method of evaluation. \n",
    "Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why\n",
    "they are interesting to someone that might use this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the different classification tasks listed, we saw the following accuracy scores from the best tuning of each classification task:  \n",
    "### For the binary target \"income\":\n",
    "#### KNN = 83.69%\n",
    "#### Random Forest = 86.37%\n",
    "#### Logistic Regression = 85.15%\n",
    "#### SVM = TBD\n",
    "  \n",
    "### For the multinomial target \"marital-status\":\n",
    "#### KNN = 74.49%\n",
    "#### Random Forest = 84.13%\n",
    "#### Logistic Regression = 84.00%\n",
    "#### SVM = TBD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • [10 points] Discuss the advantages of each model for each classification task, if any. \n",
    "If there are not advantages, explain why. Is any model better than another? Is the\n",
    "difference significant with 95% confidence? Use proper statistical comparison methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both the binomial class prediction and the multinomial class prediction it appears that Random Forest classification gave us the very best results in terms of accuracy.  In the binary class prediction there does not appear to be a major discrepancy in accuracy between the highest (random forests) and the lowest (KNN).  Furthermore, there was not a significant difference in speed of performance for any of the classification tasks run.  However, for the multinomial classification task on the target variable \"marital-status\" there was a much larger difference observed between the accuracy of the random forests classifier (84.13%) and the accuracy of the KNN classifier (74.49%).  There was little difference between using a random forest classifier and logistic regression either way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • [10 points] Which attributes from your analysis are most important? \n",
    "Use proper methods discussed in class to evaluate the importance of different attributes. Discuss\n",
    "the results and hypothesize about why certain attributes are more important than others\n",
    "for a given classification task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Deployment (5 points total)  \n",
    "### • [5 points] How useful is your model for interested parties \n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "(i.e., the companies or organizations that might want to use it for prediction)? How would you measure the\n",
    "model's value if it was used by these parties? How would your deploy your model for\n",
    "interested parties? What other data should be collected? How often would the model\n",
    "need to be updated, etc.?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizations that may be interested in our model include economists, social scientists, and legislators.  Economists will be interested in seeing what factors contribute to an individual's general income level so that they can better understand modern economical factors that affect the population (in our case US workers).  Social scientists will be interested in seeing what factors contribute to a person's marital status so that they can better understand how the economic health of a family affects the health of the marriage.  Finally, legislators and other government officials will be interested in both of these effects so that they can draft legislation to support individual welfare for their citizens and the economic health of their country as a whole.  \n",
    "  \n",
    "We would measure the model's value for these parties by how accurately it is able to predict both of its classifications.  This is because the more accurately it predicts the class of individuals in the model the more useful any action taken by the legislators and other interested parties can be expected to be.  For example, if the classification is only 20% predictive of an individuals economic or marital health, then an economist or social scientist lecturer will not be likely to include the model in their class materials.  However, if that classification is 95% accurate in predicting the class then not only will these scientists be wise to teach concepts based on the model results but that model can be used reliably in their future research.  Likewise, if a legislator drafts a new law based upon results of the model and the model is inaccurate then that law will be ineffective at combating the effects that they thought were real but were really just based on modeling error.  \n",
    "  \n",
    "For economists and social scientists we would deploy this model by sharing both the results of our model and the code that produced those results, which will allow them to perform similar classification on other populations of interest to their studies and research.  For legislators we would instead show them only the results but not the code (which they would not be trained to understand) in order to provide a proof of concept.  After obtaining funding from those legislators we would then move forward with deploying this model against Census data for their country, which would not only help train the model to that country's specific situation but would provide historical insight into the situations the country's citizens have recently found themselves in.  Finally, we would prepare the code such that when new Census data was received one could quickly feed that data into the model and receive actionable insights tailored specifically to that country's situation.  \n",
    "  \n",
    "The other data that would be collected for this model include historical Census data specific to the country for which we are applying the model (as the existing data is restricted to a population of US individuals), as well as future Census data that would be collected after the initial model had already been built.  In this situation the model would need to be updated every Census cycle as new data is collected, which for the US would be every 10 years.  If the customer for the model is an economist or social scientist that is unaffiliated with any government entity but is interested in doing their own research, then the additional data needed will be survey data from the population of interest for their research.  In this situation the model will need to be updated anytime new survey data is collected.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Exceptional Work (10 points total)\n",
    "### • You have free reign to provide additional modeling.  \n",
    "### • One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes.  \n",
    "Which parameters are most significant for making a\n",
    "good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Beware the Graveyard of Unused Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.174022</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education  education-num  marital-status  occupation  \\\n",
       "0   39          7          9             13               4           1   \n",
       "1   50          6          9             13               2           4   \n",
       "2   38          4         11              9               0           6   \n",
       "3   53          4          1              7               2           6   \n",
       "4   28          4          9             13               2          10   \n",
       "\n",
       "   relationship  race  sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0             1     4    1      2.174022             0              40   \n",
       "1             0     4    1      0.000000             0              13   \n",
       "2             1     4    1      0.000000             0              40   \n",
       "3             0     2    1      0.000000             0              40   \n",
       "4             5     2    0      0.000000             0              40   \n",
       "\n",
       "   native-country  income  \n",
       "0              39       0  \n",
       "1              39       0  \n",
       "2              39       0  \n",
       "3              39       0  \n",
       "4               5       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We did not end up using the code below as using a label encoder was inferior to creating a one-hot encoding because the \n",
    "# labelencoder assumes some positional relationship between values in our categorical variables, such as 2 being greater than 1 \n",
    "# when 2 really just represents \"divorced\" and 1 represents \"single\" or something.  As such we banished the label encoder to the \n",
    "# spooky graveyard of unused code.\n",
    "\n",
    "# This code turns all of our string entries into integer entries for the purposes of feeding them into the SVM.\n",
    "# The code in this section is based upon examples found at scikit-learn.org/stable/modules/preprocessing.html#label-encoding\n",
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df_income['workclass'] = encoder.fit_transform(df_income['workclass'])\n",
    "df_income['native-country'] = encoder.fit_transform(df_income['native-country'])\n",
    "df_income['education'] = encoder.fit_transform(df_income['education'])\n",
    "df_income['marital-status'] = encoder.fit_transform(df_income['marital-status'])\n",
    "df_income['occupation'] = encoder.fit_transform(df_income['occupation'])\n",
    "df_income['relationship'] = encoder.fit_transform(df_income['relationship'])\n",
    "df_income['race'] = encoder.fit_transform(df_income['race'])\n",
    "df_income['sex'] = encoder.fit_transform(df_income['sex'])\n",
    "\n",
    "df_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
